{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EECS 504 PS4: Backpropagation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e30b39791fd45a98820b924d1128d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41c4cfe4ea0540979c97f7cad35791f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58e17c8bacab4cf79b4941b1a348eeeb",
              "IPY_MODEL_01c9afd40c754e86837e6a9e01f64bfe"
            ]
          }
        },
        "41c4cfe4ea0540979c97f7cad35791f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58e17c8bacab4cf79b4941b1a348eeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eea4208ace8842abac04f44ba2a8bcf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_891d3a1970ce410ea7a2f8caba6f3f7d"
          }
        },
        "01c9afd40c754e86837e6a9e01f64bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa8fed0c53434c628642b58794b335c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "0it [00:00, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47c9a6be44d74085991299c3df3ad7f8"
          }
        },
        "eea4208ace8842abac04f44ba2a8bcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "891d3a1970ce410ea7a2f8caba6f3f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa8fed0c53434c628642b58794b335c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47c9a6be44d74085991299c3df3ad7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91c732fd5db14111ae75c7dc32b937a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e20d13cd9184b8bbb4d32afb794cca8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d7a2e0c8eb245cba662f125ca21c916",
              "IPY_MODEL_b80f725a95b0461282eeed99ced1668a"
            ]
          }
        },
        "8e20d13cd9184b8bbb4d32afb794cca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d7a2e0c8eb245cba662f125ca21c916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bb61ef3ca9b4b978598b9efd982f3d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd9dcc44ad7c4f819e66bf8cfed7f451"
          }
        },
        "b80f725a95b0461282eeed99ced1668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe7dcc153b4849169dd1320e7503cfa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:06, 27228483.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e03140f38844adfa65e2f99c1f440e6"
          }
        },
        "0bb61ef3ca9b4b978598b9efd982f3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd9dcc44ad7c4f819e66bf8cfed7f451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe7dcc153b4849169dd1320e7503cfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e03140f38844adfa65e2f99c1f440e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkchen1129/Computer-Vision/blob/master/EECS_504_PS4_Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix5dQS2rUMlu",
        "colab_type": "text"
      },
      "source": [
        "#EECS 504 PS4: Backpropagation\n",
        "\n",
        "Please provide the following information \n",
        "(e.g. Andrew Owens, ahowens):\n",
        "\n",
        "[PoKang] [Chen], [pkchen]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Cst4k4tuBc",
        "colab_type": "text"
      },
      "source": [
        "# Starting\n",
        "\n",
        "Run the following code to import the modules you'll need. After your finish the assignment, remember to run all cells and save the note book to your local machine as a .ipynb file for Canvas submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHumIO-xt57H",
        "colab_type": "code",
        "outputId": "ee3d1cef-12cd-4bef-e610-8fe90bde6374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "5e30b39791fd45a98820b924d1128d29",
            "41c4cfe4ea0540979c97f7cad35791f0",
            "58e17c8bacab4cf79b4941b1a348eeeb",
            "01c9afd40c754e86837e6a9e01f64bfe",
            "eea4208ace8842abac04f44ba2a8bcf3",
            "891d3a1970ce410ea7a2f8caba6f3f7d",
            "fa8fed0c53434c628642b58794b335c7",
            "47c9a6be44d74085991299c3df3ad7f8",
            "91c732fd5db14111ae75c7dc32b937a6",
            "8e20d13cd9184b8bbb4d32afb794cca8",
            "7d7a2e0c8eb245cba662f125ca21c916",
            "b80f725a95b0461282eeed99ced1668a",
            "0bb61ef3ca9b4b978598b9efd982f3d9",
            "dd9dcc44ad7c4f819e66bf8cfed7f451",
            "fe7dcc153b4849169dd1320e7503cfa3",
            "0e03140f38844adfa65e2f99c1f440e6"
          ]
        }
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision.datasets import CIFAR10\n",
        "download = not os.path.isdir('cifar-10-batches-py')\n",
        "dset_train = CIFAR10(root='.', download=download)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e30b39791fd45a98820b924d1128d29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Failed download. Trying https -> http instead. Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91c732fd5db14111ae75c7dc32b937a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apEPzDNtK0MC",
        "colab_type": "text"
      },
      "source": [
        "# Problem 4.2 Multi-layer perceptron\n",
        "In this problem you will develop a two Layer neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset.\n",
        "\n",
        "We train the network with a softmax loss function on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture:\n",
        "\n",
        "input - fully connected layer - ReLU - fully connected layer - softmax\n",
        "\n",
        "The outputs of the second fully-connected layer are the scores for each class.\n",
        "\n",
        "You cannot use any deep learning libraries such as PyTorch in this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXfumCQ21JoK",
        "colab_type": "text"
      },
      "source": [
        "# 4.2 (a) Layers\n",
        "In this problem, implement fully connected layer, relu and softmax. Filling in all TODOs in skeleton codes will be sufficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ljfgMv9PHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From Justin Johnson:\n",
        "    #http://cs231n.stanford.edu/handouts/linear-backprop.pdf\n",
        "    #https://deepnotes.io/softmax-crossentropy\n",
        "\n",
        "def fc_forward(x, w, b):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a fully-connected layer.\n",
        "    \n",
        "    The input x has shape (N, Din) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (Din,).\n",
        "    \n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, Din)\n",
        "    - w: A numpy array of weights, of shape (Din, Dout)\n",
        "    - b: A numpy array of biases, of shape (Dout,)\n",
        "    \n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, Dout)\n",
        "    - cache: (x, w, b)\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the forward pass. Store the result in out.              #\n",
        "    ###########################################################################\n",
        "\n",
        "    out = x @ w + b\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = (x, w, b)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def fc_backward(dout, cache):\n",
        "    \n",
        "    \"\"\"\n",
        "    Computes the backward pass for a fully_connected layer.\n",
        "    \n",
        "    Inputs:\n",
        "    - dout: Upstream derivative, of shape (N, Dout)\n",
        "    - cache: returned by your forward function. Tuple of:\n",
        "      - x: Input data, of shape (N, Din)\n",
        "      - w: Weights, of shape (Din, Dout)\n",
        "      - b: Biases, of shape (Dout,)\n",
        "      \n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, Din)\n",
        "    - dw: Gradient with respect to w, of shape (Din, Dout)\n",
        "    - db: Gradient with respect to b, of shape (Dout,)\n",
        "    \"\"\"\n",
        "    x, w, b = cache\n",
        "    dx, dw, db = None, None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the affine backward pass.                               #\n",
        "    ###########################################################################\n",
        "    dx = dout @ w.T  # (N,Dout) * (Din,Dout)' = (N, Din)\n",
        "    dw = x.T @ dout  #  (N, Din)' * (N,Dout)  = (Din, Dout)  \n",
        "    db = np.sum(dout , axis = 0) #####\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dx, dw, db\n",
        "\n",
        "def relu_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - x: Inputs, of any shape\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output, of the same shape as x\n",
        "    - cache: x\n",
        "    \"\"\"\n",
        "    out = x\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU forward pass.                                  #\n",
        "    ###########################################################################\n",
        "    out = np.maximum(0, out)\n",
        "    \n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = x\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def relu_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - dout: Upstream derivatives, of any shape\n",
        "    - cache: returned by your forward function. Input x, of same shape as dout\n",
        "\n",
        "    Returns:\n",
        "    - dx: Gradient with respect to x\n",
        "    \"\"\"\n",
        "    dx, x = dout, cache\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU backward pass.                                 #\n",
        "    ###########################################################################\n",
        "    out = np.maximum(0, x) \n",
        "    out[out > 0 ] = 1\n",
        "    dx = out * dout\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dx\n",
        "def softmax(x):\n",
        "    \n",
        "    probs = np.exp(x - np.max(x, axis=1, keepdims = True)) #keepdims\n",
        "    sm /= np.sum(probs, axis=1, keepdims = True)\n",
        "    return sm\n",
        "\n",
        "def softmax_loss(x, y):\n",
        "    \"\"\"\n",
        "    Computes the loss and gradient for softmax classification.\n",
        "\n",
        "    Inputs:\n",
        "    - x: Input data, of shape (N, C) where x[i, j] is the score for the jth\n",
        "      class for the ith input.\n",
        "    - y: Vector of labels, of shape (N,) where y[i] is the label for x[i] and\n",
        "      0 <= y[i] < C\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - loss: Scalar giving the loss\n",
        "    - dx: Gradient of the loss with respect to x\n",
        "    \"\"\"\n",
        "    loss, dx = None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement softmax loss                                            #\n",
        "    ###########################################################################\n",
        "    \n",
        "\n",
        "    #softmax\n",
        "    probs = np.exp(x - np.max(x, axis=1, keepdims=True)) #keepdims\n",
        "    probs /= np.sum(probs, axis=1, keepdims=True)\n",
        "    \n",
        "    #Loss\n",
        "    N = x.shape[0]\n",
        "    loss = -np.sum(np.log(probs[np.arange(N), y])) / N\n",
        "\n",
        "    #Grad \n",
        "    dx = probs.copy()\n",
        "    dx[np.arange(N), y] -= 1\n",
        "    dx /= N\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return loss, dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFxtS3zK8oz",
        "colab_type": "text"
      },
      "source": [
        "# 4.2 (b) Softmax Classifier\n",
        "\n",
        "In this problem, implement softmax classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytvxbx9UpxVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SoftmaxClassifier(object):\n",
        "    \"\"\"\n",
        "    A fully-connected neural network with\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecture should be fc - relu - fc - softmax with one hidden layer\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=3072, hidden_dim=300, num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        Initialize a new network.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: An integer giving the size of the input\n",
        "        - hidden_dim: An integer giving the size of the hidden layer, None\n",
        "          if there's no hidden layer.\n",
        "        - num_classes: An integer giving the number of classes to classify\n",
        "        - weight_scale: Scalar giving the standard deviation for random\n",
        "          initialization of the weights.\n",
        "        \"\"\"\n",
        "        self.params = {}\n",
        "        ############################################################################\n",
        "        # TODO: Initialize the weights and biases of the two-layer net. Weights    #\n",
        "        # should be initialized from a Gaussian centered at 0.0 with               #\n",
        "        # standard deviation equal to weight_scale, and biases should be           #\n",
        "        # initialized to zero. All weights and biases should be stored in the      #\n",
        "        # dictionary self.params, with fc weights and biases using the keys        #\n",
        "        # 'W' and 'b', i.e., W1, b1 for the weights and bias in the first linear   #\n",
        "        # layer, W2, b2 for the weights and bias in the second linear layer.       #\n",
        "        ############################################################################\n",
        "        # self.hidden_dim = \n",
        "\n",
        "        self.params['W1'] = np.random.normal(scale=weight_scale, size=(input_dim, hidden_dim))\n",
        "        self.params['W2'] = np.random.normal(scale=weight_scale, size=(hidden_dim, num_classes))\n",
        "        self.params['b1'] = np.zeros(hidden_dim)\n",
        "        self.params['b2'] = np.zeros(num_classes)\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "\n",
        "    def forwards_backwards(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute loss and gradient for a minibatch of data.\n",
        "\n",
        "        Inputs:\n",
        "        - X: Array of input data of shape (N, Din)\n",
        "        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].\n",
        "\n",
        "        Returns:\n",
        "        If y is None, then run a test-time forward pass of the model and return:\n",
        "        - scores: Array of shape (N, C) giving classification scores, where\n",
        "          scores[i, c] is the classification score for X[i] and class c.\n",
        "\n",
        "        If y is not None, then run a training-time forward and backward pass. And\n",
        "        return a tuple of:\n",
        "        - loss: Scalar value giving the loss\n",
        "        - grads: Dictionary with the same keys as self.params, mapping parameter\n",
        "          names to gradients of the loss with respect to those parameters.\n",
        "        \"\"\"\n",
        "        scores = None\n",
        "        ############################################################################\n",
        "        # TODO: Implement the forward pass for the two-layer net, computing the    #\n",
        "        # class scores for X and storing them in the scores variable.              #\n",
        "        ############################################################################\n",
        "        out_1, cache_1 = fc_forward(X, self.params['W1'], self.params['b1'])\n",
        "        out_2, cache_2 = relu_forward(out_1)\n",
        "        out_3, cache_3 = fc_forward(out_2, self.params['W2'], self.params['b2'])\n",
        "\n",
        "        scores = out_3\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        # If y is None then we are in test mode so just return scores\n",
        "        if y is None:\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0, {}\n",
        "        ############################################################################\n",
        "        # TODO: Implement the backward pass for the two-layer net. Store the loss  #\n",
        "        # in the loss variable and gradients in the grads dictionary. Compute data #\n",
        "        # loss using softmax, and make sure that grads[k] holds the gradients for  #\n",
        "        # self.params[k].                                                          # \n",
        "        ############################################################################\n",
        "        loss, dscores = softmax_loss(scores, y)\n",
        "        dx_3, grads['W2'], grads['b2'] = fc_backward(dscores, cache_3)\n",
        "        dx_2 = relu_backward(dx_3, cache_2)\n",
        "        dx_1, grads['W1'], grads['b1'] = fc_backward(dx_2, cache_1)\n",
        "\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "        return loss, grads\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwp0waIL1h_e",
        "colab_type": "text"
      },
      "source": [
        "# 4.2(c) Training\n",
        "\n",
        "In this problem, you need to preprocess the images and set up model hyperparameters. Notice that adjust the training and val split is optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZPtQzXGMoCg",
        "colab_type": "code",
        "outputId": "542151fd-166e-40e8-bf27-b768ed505657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding=\"latin1\")\n",
        "    return dict\n",
        "\n",
        "def load_cifar10():\n",
        "    data = {}\n",
        "    meta = unpickle(\"cifar-10-batches-py/batches.meta\")\n",
        "    batch1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
        "    batch2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
        "    batch3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
        "    batch4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
        "    batch5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
        "    test_batch = unpickle(\"cifar-10-batches-py/test_batch\")\n",
        "    X_train = np.vstack((batch1['data'], batch2['data'], batch3['data'],\\\n",
        "                         batch4['data'], batch5['data']))\n",
        "    Y_train = np.array(batch1['labels'] + batch2['labels'] + batch3['labels'] + \n",
        "                       batch4['labels'] + batch5['labels'])\n",
        "    X_test = test_batch['data']\n",
        "    Y_test = test_batch['labels']\n",
        "    \n",
        "    #Preprocess images here                                     \n",
        "    X_train = (X_train-np.mean(X_train,axis=1,keepdims=True))/np.std(X_train,axis=1,keepdims=True)\n",
        "    X_test = (X_test-np.mean(X_test,axis=1,keepdims=True))/np.std(X_test,axis=1,keepdims=True)\n",
        "\n",
        "    data['X_train'] = X_train[:40000]\n",
        "    data['y_train'] = Y_train[:40000]\n",
        "    data['X_val'] = X_train[40000:]\n",
        "    data['y_val'] = Y_train[40000:]\n",
        "    data['X_test'] = X_test\n",
        "    data['y_test'] = Y_test\n",
        "    return data\n",
        "\n",
        "def test_network(model, X, y, num_samples=None, batch_size=100):\n",
        "    \"\"\"\n",
        "    Check accuracy of the model on the provided data.\n",
        "\n",
        "    Inputs:\n",
        "    - model: Image classifier\n",
        "    - X: Array of data, of shape (N, d_1, ..., d_k)\n",
        "    - y: Array of labels, of shape (N,)\n",
        "    - num_samples: If not None, subsample the data and only test the model\n",
        "      on num_samples datapoints.\n",
        "    - batch_size: Split X and y into batches of this size to avoid using\n",
        "      too much memory.\n",
        "\n",
        "    Returns:\n",
        "    - acc: Scalar giving the fraction of instances that were correctly\n",
        "      classified by the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Subsample the data\n",
        "    N = X.shape[0]\n",
        "    if num_samples is not None and N > num_samples:\n",
        "        mask = np.random.choice(N, num_samples)\n",
        "        N = num_samples\n",
        "        X = X[mask]\n",
        "        y = y[mask]\n",
        "\n",
        "    # Compute predictions in batches\n",
        "    num_batches = N // batch_size\n",
        "    if N % batch_size != 0:\n",
        "        num_batches += 1\n",
        "    y_pred = []\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        scores = model.forwards_backwards(X[start:end])\n",
        "        y_pred.append(np.argmax(scores, axis=1))\n",
        "    y_pred = np.hstack(y_pred)\n",
        "    acc = np.mean(y_pred == y)\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train_network(model, data, **kwargs):\n",
        "    \"\"\"\n",
        "     Required arguments:\n",
        "    - model: Image classifier\n",
        "    - data: A dictionary of training and validation data containing:\n",
        "      'X_train': Array, shape (N_train, d_1, ..., d_k) of training images\n",
        "      'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images\n",
        "      'y_train': Array, shape (N_train,) of labels for training images\n",
        "      'y_val': Array, shape (N_val,) of labels for validation images\n",
        "\n",
        "    Optional arguments:\n",
        "    - learning_rate: A scalar for initial learning rate.\n",
        "    - lr_decay: A scalar for learning rate decay; after each epoch the\n",
        "      learning rate is multiplied by this value.\n",
        "    - batch_size: Size of minibatches used to compute loss and gradient\n",
        "      during training.\n",
        "    - num_epochs: The number of epochs to run for during training.\n",
        "    - print_every: Integer; training losses will be printed every\n",
        "      print_every iterations.\n",
        "    - verbose: Boolean; if set to false then no output will be printed\n",
        "      during training.\n",
        "    - num_train_samples: Number of training samples used to check training\n",
        "      accuracy; default is 1000; set to None to use entire training set.\n",
        "    - num_val_samples: Number of validation samples to use to check val\n",
        "      accuracy; default is None, which uses the entire validation set.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    learning_rate =  kwargs.pop('learning_rate', 1e-3)\n",
        "    lr_decay = kwargs.pop('lr_decay', 1.0)\n",
        "    batch_size = kwargs.pop('batch_size', 100)\n",
        "    num_epochs = kwargs.pop('num_epochs', 10)\n",
        "    num_train_samples = kwargs.pop('num_train_samples', 1000)\n",
        "    num_val_samples = kwargs.pop('num_val_samples', None)\n",
        "    print_every = kwargs.pop('print_every', 10)   \n",
        "    verbose = kwargs.pop('verbose', True)\n",
        "    \n",
        "    epoch = 0\n",
        "    best_val_acc = 0\n",
        "    best_params = {}\n",
        "    loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "    \n",
        "    \n",
        "    num_train = data['X_train'].shape[0]\n",
        "    iterations_per_epoch = max(num_train // batch_size, 1)\n",
        "    num_iterations = num_epochs * iterations_per_epoch\n",
        "    \n",
        "\n",
        "    \n",
        "    for t in range(num_iterations):\n",
        "        # Make a minibatch of training data\n",
        "        batch_mask = np.random.choice(num_train, batch_size)\n",
        "        X_batch = data['X_train'][batch_mask]\n",
        "        y_batch = data['y_train'][batch_mask]\n",
        "        \n",
        "        # Compute loss and gradient\n",
        "        loss, grads = model.forwards_backwards(X_batch, y_batch)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in model.params.items():\n",
        "            model.params[p] = w - grads[p]*learning_rate\n",
        "          \n",
        "        # Print training loss\n",
        "        if verbose and t % print_every == 0:\n",
        "            print('(Iteration %d / %d) loss: %f' % (\n",
        "                   t + 1, num_iterations, loss_history[-1]))\n",
        "         \n",
        "        # At the end of every epoch, increment the epoch counter and decay\n",
        "        # the learning rate.\n",
        "        epoch_end = (t + 1) % iterations_per_epoch == 0\n",
        "        if epoch_end:\n",
        "            epoch += 1\n",
        "            learning_rate *= lr_decay\n",
        "        \n",
        "        # Check train and val accuracy on the first iteration, the last\n",
        "        # iteration, and at the end of each epoch.\n",
        "        first_it = (t == 0)\n",
        "        last_it = (t == num_iterations - 1)\n",
        "        if first_it or last_it or epoch_end:\n",
        "            train_acc = test_network(model, data['X_train'], data['y_train'],\n",
        "                num_samples= num_train_samples)\n",
        "            val_acc = test_network(model, data['X_val'], data['y_val'],\n",
        "                num_samples=num_val_samples)\n",
        "            train_acc_history.append(train_acc)\n",
        "            val_acc_history.append(val_acc)\n",
        "\n",
        "            if verbose:\n",
        "                print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
        "                       epoch, num_epochs, train_acc, val_acc))\n",
        "\n",
        "            # Keep track of the best model\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_params = {}\n",
        "                for k, v in model.params.items():\n",
        "                    best_params[k] = v.copy()\n",
        "        \n",
        "    model.params = best_params\n",
        "        \n",
        "    return model, train_acc_history, val_acc_history\n",
        "        \n",
        "\n",
        "# load data\n",
        "data = load_cifar10() \n",
        "train_data = { k: data[k] for k in ['X_train', 'y_train', \n",
        "                                    'X_val', 'y_val']}\n",
        "#######################################################################\n",
        "# TODO: Set up model hyperparameters                                  #\n",
        "#######################################################################\n",
        "\n",
        "# initialize model\n",
        "model = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
        "\n",
        "# start training    \n",
        "model, train_acc_history, val_acc_history = train_network(\n",
        "    model, train_data, learning_rate = 0.01,\n",
        "    lr_decay= 1, num_epochs = 15, \n",
        "    batch_size= 256, print_every=1000)\n",
        "#######################################################################\n",
        "#                         END OF YOUR CODE                            #\n",
        "#######################################################################\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 2340) loss: 2.294693\n",
            "(Epoch 0 / 15) train acc: 0.114000; val_acc: 0.117000\n",
            "(Epoch 1 / 15) train acc: 0.338000; val_acc: 0.315900\n",
            "(Epoch 2 / 15) train acc: 0.385000; val_acc: 0.352000\n",
            "(Epoch 3 / 15) train acc: 0.405000; val_acc: 0.377100\n",
            "(Epoch 4 / 15) train acc: 0.423000; val_acc: 0.392600\n",
            "(Epoch 5 / 15) train acc: 0.438000; val_acc: 0.412300\n",
            "(Epoch 6 / 15) train acc: 0.432000; val_acc: 0.421000\n",
            "(Iteration 1001 / 2340) loss: 1.580189\n",
            "(Epoch 7 / 15) train acc: 0.460000; val_acc: 0.427500\n",
            "(Epoch 8 / 15) train acc: 0.441000; val_acc: 0.436700\n",
            "(Epoch 9 / 15) train acc: 0.492000; val_acc: 0.442500\n",
            "(Epoch 10 / 15) train acc: 0.488000; val_acc: 0.448400\n",
            "(Epoch 11 / 15) train acc: 0.497000; val_acc: 0.456700\n",
            "(Epoch 12 / 15) train acc: 0.503000; val_acc: 0.461200\n",
            "(Iteration 2001 / 2340) loss: 1.427029\n",
            "(Epoch 13 / 15) train acc: 0.493000; val_acc: 0.463800\n",
            "(Epoch 14 / 15) train acc: 0.506000; val_acc: 0.470900\n",
            "(Epoch 15 / 15) train acc: 0.512000; val_acc: 0.477200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcovGmpXvXXa",
        "colab_type": "text"
      },
      "source": [
        "# 4.2(c) Report Accuracy\n",
        "\n",
        "Run the given code and report the accuracy on test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwCq8pBhu6dz",
        "colab_type": "code",
        "outputId": "86fd7ce0-3330-4673-dbb7-6f93f1f27b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# report test accuracy\n",
        "acc = test_network(model, data['X_test'], data['y_test'])\n",
        "print(\"Test accuracy: {}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.4811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTrmbULS7i2N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 4.2(d) Plot\n",
        "\n",
        "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPjtnbya9S7g",
        "colab_type": "code",
        "outputId": "f0eddc7f-86f4-4bc3-e391-3e7f4208ea06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "a = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(a , train_acc_history, label = 'Train accuracy')\n",
        "plt.plot(a , val_acc_history , label = 'Value Accuracy')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Train & Val accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7c93981b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}